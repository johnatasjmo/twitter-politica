---
title: "lookupfollowers"
author: "Johnatas Montezuma"
date: "10/11/2019"
output: html_document
---

# Load followers_list
```{r}
followers_list <- readRDS(paste0(data_folder, "/followers_list.Rds"))
```


# Lookup basic data of all followers of accounts
```{r}
### test select 100000 accounts and lookup for users as vector
## followers_list <- top_n(followers_list, 100000)
followers_list <- as.vector(unlist(followers_list))
```


How long is the followers_list?
```{r}
prettyNum(length(followers_list), big.mark = ",") 
#### 6,159,120
```

create function for chunk
```{r}
### this function receives a list and divides it into lists of n length
chunk <- function(x,n)
{
        f <- sort(rep(1:(trunc(length(x)/n)+1),n))[1:length(x)]
        return(split(x,f))
}
```


split follower list in batches of 3 hours each
```{r}
batch.size <- 1080000
batches <- chunk(followers_list, n = batch.size)
### assign a variable to each batch
batch1 <- batches[[1]]
batch2 <- batches[[2]]
batch3 <- batches[[3]]
batch4 <- batches[[4]]
batch5 <- batches[[5]]
batch6 <- batches[[6]]
## save batches
saveRDS(batch1, file = paste0(data_folder, "/tmp/batch1.Rds"))
saveRDS(batch2, file = paste0(data_folder, "/tmp/batch2.Rds"))
saveRDS(batch3, file = paste0(data_folder, "/tmp/batch3.Rds"))
saveRDS(batch4, file = paste0(data_folder, "/tmp/batch4.Rds"))
saveRDS(batch5, file = paste0(data_folder, "/tmp/batch5.Rds"))
saveRDS(batch6, file = paste0(data_folder, "/tmp/batch6.Rds"))
## remove batches to release R memory
rm(batch2, batch3, batch4, batch5, batch6)
## clean up
rm(batches, batch.size)
```


### Read batches and lookup_users for each batch
Read batch1, repeat until the last batch
```{r}
batch3 <- readRDS(paste0(data_folder, "/tmp/batch3.Rds"))
```

Get followers data for each batch
```{r}
### get the list of users per batch. Start with batch1 until batchX
users <- batch3
### set API limit of chunks (90000 for lookup_users)
limit <- 90000
### create chunks equal to limit size
chunks <-chunk(users,limit)
### lenght of chunks
n <- length(chunks)
### create data vector with length of chunks change data1, 2, 3 each time
data <- vector("list", n)
### estimate time for running the loop. Aprox 360K per hour
cat("This loop will take ", n/3, "hours, ending ", format(Sys.time()+n*900, "%a %b %d %X"))
### execute for loop in chunks and sleep
for (i in seq_along(chunks)) {
        data[[i]] <- lookup_users(chunks[[i]])
        ## print progress and sleep 15 minutes
        cat(i, "/", n, " ", sep = "")
        Sys.sleep(900)
}
### END LOOP
rm(i, n, limit, chunks, users)
## finish notice
cat("loop finished at", format(Sys.time(), "%a %b %d %X %Y"))
```

Put all together - change data name, where batch1 becomes data1
```{r}
batch2_data <- data
rm(data) # removing data for future use
```

### save files for future use
```{r}
saveRDS(batch2_data, file = paste0(data_folder, "/tmp/batch2_data.Rds"))
```


Saving files for future use
```{r}
file.name <- paste0(followers_folder, "followers_df.rdata")
save(user_followers_df, file = file.name)
```


Clean up variables
```{r}
## Clean. Remove variables
rm(users, user_followers, file.name, i, n, limit, chunk, chunks, n, data, user_followers_df)
```

